{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00934028",
   "metadata": {
    "papermill": {
     "duration": 0.008271,
     "end_time": "2024-12-27T06:43:28.281694",
     "exception": false,
     "start_time": "2024-12-27T06:43:28.273423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d054adc7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:28.295577Z",
     "iopub.status.busy": "2024-12-27T06:43:28.294757Z",
     "iopub.status.idle": "2024-12-27T06:43:39.194251Z",
     "shell.execute_reply": "2024-12-27T06:43:39.192647Z"
    },
    "papermill": {
     "duration": 10.909224,
     "end_time": "2024-12-27T06:43:39.197012",
     "exception": false,
     "start_time": "2024-12-27T06:43:28.287788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports for neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "# imports for vision tasks\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import pydicom\n",
    "\n",
    "# imports for preparing dataset\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "# imports for visualizations\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Tuple, List, Optional, Union, Any\n",
    "import platform\n",
    "from enum import Enum\n",
    "import timm\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve, \n",
    "    auc,\n",
    "    accuracy_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88e64e",
   "metadata": {
    "papermill": {
     "duration": 0.005492,
     "end_time": "2024-12-27T06:43:39.208596",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.203104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14f544",
   "metadata": {
    "papermill": {
     "duration": 0.007933,
     "end_time": "2024-12-27T06:43:39.223398",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.215465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Data Structure Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888bccd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.239888Z",
     "iopub.status.busy": "2024-12-27T06:43:39.239236Z",
     "iopub.status.idle": "2024-12-27T06:43:39.247337Z",
     "shell.execute_reply": "2024-12-27T06:43:39.246070Z"
    },
    "papermill": {
     "duration": 0.017547,
     "end_time": "2024-12-27T06:43:39.249602",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.232055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpinalConditionDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class with optimized device handling\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        images: torch.Tensor, \n",
    "        labels: torch.Tensor, \n",
    "        metadata: pd.DataFrame,\n",
    "        device: Optional[torch.device] = None\n",
    "    ):\n",
    "        if device is None:\n",
    "            self.device, self.device_type = get_best_available_device()\n",
    "        else:\n",
    "            self.device = device\n",
    "            self.device_type = device.type\n",
    "        \n",
    "        # Store as CPU tensors initially\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Move individual items to device when accessed\n",
    "        image = self.images[idx].to(self.device)\n",
    "        label = self.labels[idx].to(self.device)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89735fad",
   "metadata": {
    "papermill": {
     "duration": 0.005605,
     "end_time": "2024-12-27T06:43:39.261311",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.255706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Premade Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3b507",
   "metadata": {
    "papermill": {
     "duration": 0.00581,
     "end_time": "2024-12-27T06:43:39.273247",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.267437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting Best Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbd9b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.286729Z",
     "iopub.status.busy": "2024-12-27T06:43:39.286331Z",
     "iopub.status.idle": "2024-12-27T06:43:39.293958Z",
     "shell.execute_reply": "2024-12-27T06:43:39.292663Z"
    },
    "papermill": {
     "duration": 0.016713,
     "end_time": "2024-12-27T06:43:39.295872",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.279159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_available_device() -> Tuple[torch.device, str]:\n",
    "    \"\"\"\n",
    "    Detect and return the best available device for tensor operations.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[torch.device, str]: Device object and device type string\n",
    "    \"\"\"\n",
    "    device_type = \"cpu\"\n",
    "    \n",
    "    # Check for CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = \"cuda\"\n",
    "        \n",
    "    # Check for Apple M1/M2 MPS (Metal Performance Shaders)\n",
    "    elif platform.processor().startswith('arm') and platform.system() == 'Darwin' and \\\n",
    "         hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device_type = \"mps\"\n",
    "        \n",
    "    # Check for TPU (if torch_xla is available)\n",
    "    try:\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        device_type = \"tpu\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "        \n",
    "    # Create device object based on type\n",
    "    if device_type == \"tpu\":\n",
    "        try:\n",
    "            device = xm.xla_device()\n",
    "        except NameError:\n",
    "            device = torch.device(\"cpu\")\n",
    "            device_type = \"cpu\"\n",
    "    else:\n",
    "        device = torch.device(device_type)\n",
    "        \n",
    "    return device, device_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc7b77",
   "metadata": {
    "papermill": {
     "duration": 0.005868,
     "end_time": "2024-12-27T06:43:39.307829",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.301961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1004dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.322800Z",
     "iopub.status.busy": "2024-12-27T06:43:39.322354Z",
     "iopub.status.idle": "2024-12-27T06:43:39.331142Z",
     "shell.execute_reply": "2024-12-27T06:43:39.330021Z"
    },
    "papermill": {
     "duration": 0.018715,
     "end_time": "2024-12-27T06:43:39.333257",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.314542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_processed_dataset(base_load_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Load the processed dataset from disk.\n",
    "    \n",
    "    Args:\n",
    "        base_load_path (str): Path where the dataset is saved\n",
    "    \n",
    "    Returns:\n",
    "        dict: Loaded condition data\n",
    "        dict: Configuration data\n",
    "    \"\"\"\n",
    "    base_path = Path(base_load_path)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        raise ValueError(f\"Dataset path {base_path} does not exist\")\n",
    "    \n",
    "    # Load configuration\n",
    "    with open(base_path / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Initialize condition data dictionary\n",
    "    loaded_condition_data = {}\n",
    "    \n",
    "    # Load data for each condition\n",
    "    for condition in config['core_conditions']:\n",
    "        condition_path = base_path / condition\n",
    "        \n",
    "        if condition_path.exists():\n",
    "            loaded_condition_data[condition] = {\n",
    "                'images': torch.load(condition_path / 'images.pt', weights_only=False),\n",
    "                'labels': torch.load(condition_path / 'labels.pt', weights_only=False),\n",
    "                'metadata': pd.read_pickle(condition_path / 'metadata.pkl')\n",
    "            }\n",
    "    \n",
    "    if verbose is True :\n",
    "        print(\"\\nDataset successfully loaded\")\n",
    "        print(\"\\nDataset Summary:\")\n",
    "        for condition, data in loaded_condition_data.items():\n",
    "            print(f\"\\n{condition}:\")\n",
    "            print(f\"Total samples: {len(data['images'])}\")\n",
    "            label_dist = torch.bincount(data['labels'])\n",
    "            for severity, idx in config['severity_mapping'].items():\n",
    "                if idx < len(label_dist):\n",
    "                    print(f\"  {severity}: {label_dist[idx].item()}\")\n",
    "    \n",
    "    return loaded_condition_data, config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e68428",
   "metadata": {
    "papermill": {
     "duration": 0.00554,
     "end_time": "2024-12-27T06:43:39.344595",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.339055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Splitting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880538ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.358064Z",
     "iopub.status.busy": "2024-12-27T06:43:39.357663Z",
     "iopub.status.idle": "2024-12-27T06:43:39.365486Z",
     "shell.execute_reply": "2024-12-27T06:43:39.364455Z"
    },
    "papermill": {
     "duration": 0.017693,
     "end_time": "2024-12-27T06:43:39.368104",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.350411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_train_val_split(\n",
    "    condition_data: Dict,\n",
    "    device: Optional[torch.device] = None,\n",
    "    val_ratio: float = 0.2,\n",
    "    seed: int = 42\n",
    ") -> Dict[str, Dict[str, Dict]]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation sets with automatic device support.\n",
    "    \n",
    "    Args:\n",
    "        condition_data (Dict): Dictionary containing data for each condition\n",
    "        device (Optional[torch.device]): Device to store the tensors on\n",
    "        val_ratio (float): Ratio of validation set size to total dataset size\n",
    "        seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Dictionary containing train and val splits for each condition\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    split_data = {\n",
    "        'train': {},\n",
    "        'val': {}\n",
    "    }\n",
    "    \n",
    "    for condition, data in condition_data.items():\n",
    "        dataset_size = len(data['images'])\n",
    "        val_size = int(dataset_size * val_ratio)\n",
    "        train_size = dataset_size - val_size\n",
    "        \n",
    "        # Create full dataset with device specification\n",
    "        full_dataset = SpinalConditionDataset(\n",
    "            data['images'],\n",
    "            data['labels'],\n",
    "            data['metadata'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Split dataset\n",
    "        train_dataset, val_dataset = random_split(\n",
    "            full_dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(seed)\n",
    "        )\n",
    "        \n",
    "        split_data['train'][condition] = train_dataset\n",
    "        split_data['val'][condition] = val_dataset\n",
    "        \n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75d7e2",
   "metadata": {
    "papermill": {
     "duration": 0.008494,
     "end_time": "2024-12-27T06:43:39.384628",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.376134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Loader Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea01f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.401381Z",
     "iopub.status.busy": "2024-12-27T06:43:39.400838Z",
     "iopub.status.idle": "2024-12-27T06:43:39.414088Z",
     "shell.execute_reply": "2024-12-27T06:43:39.412718Z"
    },
    "papermill": {
     "duration": 0.024956,
     "end_time": "2024-12-27T06:43:39.417445",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.392489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    split_data: Dict[str, Dict[str, Dataset]],\n",
    "    device_type: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4,\n",
    "    shuffle_train: bool = True\n",
    ") -> Dict[str, Dict[str, DataLoader]]:\n",
    "    \"\"\"\n",
    "    Create DataLoader objects optimized for the detected device.\n",
    "    \n",
    "    Args:\n",
    "        split_data (Dict): Dictionary containing train and val splits\n",
    "        device_type (str): Type of device being used\n",
    "        batch_size (int): Batch size for DataLoader\n",
    "        num_workers (int): Number of worker processes\n",
    "        shuffle_train (bool): Whether to shuffle training data\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Dictionary containing DataLoader objects for each split and condition\n",
    "    \"\"\"\n",
    "    dataloaders = {\n",
    "        'train': {},\n",
    "        'val': {}\n",
    "    }\n",
    "    \n",
    "    # Optimize DataLoader settings based on device\n",
    "    if device_type == \"cuda\":\n",
    "        pin_memory = False  # Data is already on GPU\n",
    "    elif device_type == \"tpu\":\n",
    "        pin_memory = False\n",
    "        num_workers = 0  # TPU often works better with synchronous loading\n",
    "    else:  # CPU or MPS\n",
    "        pin_memory = True\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        for condition, dataset in split_data[split].items():\n",
    "            dataloaders[split][condition] = DataLoader(\n",
    "                dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=(shuffle_train and split == 'train'),\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory\n",
    "            )\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32afa4",
   "metadata": {
    "papermill": {
     "duration": 0.007485,
     "end_time": "2024-12-27T06:43:39.436400",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.428915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11100c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.456868Z",
     "iopub.status.busy": "2024-12-27T06:43:39.456298Z",
     "iopub.status.idle": "2024-12-27T06:43:39.464382Z",
     "shell.execute_reply": "2024-12-27T06:43:39.463100Z"
    },
    "papermill": {
     "duration": 0.024031,
     "end_time": "2024-12-27T06:43:39.467724",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.443693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device_specific_batch_size(device_type: str, base_batch_size: int) -> int:\n",
    "    \"\"\"\n",
    "    Adjust batch size based on device type and available memory.\n",
    "    \n",
    "    Args:\n",
    "        device_type (str): Type of device being used\n",
    "        base_batch_size (int): Requested batch size\n",
    "        \n",
    "    Returns:\n",
    "        int: Adjusted batch size\n",
    "    \"\"\"\n",
    "    if device_type == \"cuda\":\n",
    "        # Get available GPU memory and adjust batch size if needed\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "        if gpu_memory < 8 * (1024**3):  # Less than 8GB\n",
    "            return min(base_batch_size, 16)\n",
    "    elif device_type == \"tpu\":\n",
    "        # TPUs often work better with larger batch sizes\n",
    "        return max(base_batch_size, 128)\n",
    "    \n",
    "    return base_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c1f5b",
   "metadata": {
    "papermill": {
     "duration": 0.00538,
     "end_time": "2024-12-27T06:43:39.479443",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.474063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Usage Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f609fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.492830Z",
     "iopub.status.busy": "2024-12-27T06:43:39.492481Z",
     "iopub.status.idle": "2024-12-27T06:43:39.503106Z",
     "shell.execute_reply": "2024-12-27T06:43:39.501777Z"
    },
    "papermill": {
     "duration": 0.020236,
     "end_time": "2024-12-27T06:43:39.505355",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.485119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(\n",
    "    base_load_path: str,\n",
    "    batch_size: int = 32,\n",
    "    val_ratio: float = 0.2,\n",
    "    num_workers: int = 4,\n",
    "    seed: int = 42,\n",
    "    verbose: bool = False\n",
    ") -> Tuple[Dict, Dict, Dict, torch.device]:\n",
    "    \"\"\"\n",
    "    Load and prepare data loaders with automatic device detection and optimization.\n",
    "    \n",
    "    Args:\n",
    "        base_load_path (str): Path to dataset\n",
    "        batch_size (int): Base batch size for DataLoader\n",
    "        val_ratio (float): Validation set ratio\n",
    "        num_workers (int): Number of worker processes\n",
    "        seed (int): Random seed\n",
    "        verbose (bool): Whether to print dataset information\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Dictionary of dataloaders\n",
    "        - Dictionary of split datasets\n",
    "        - Configuration dictionary\n",
    "        - Device being used\n",
    "    \"\"\"\n",
    "    # Detect best available device\n",
    "    device, device_type = get_best_available_device()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nUsing device: {device} ({device_type})\")\n",
    "    \n",
    "    # Adjust batch size for device\n",
    "    adjusted_batch_size = get_device_specific_batch_size(device_type, batch_size)\n",
    "    if verbose and adjusted_batch_size != batch_size:\n",
    "        print(f\"Adjusted batch size from {batch_size} to {adjusted_batch_size} for {device_type}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    condition_data, config = load_processed_dataset(base_load_path, verbose=verbose)\n",
    "    \n",
    "    # Create train/val split\n",
    "    split_data = create_train_val_split(\n",
    "        condition_data,\n",
    "        device=device,\n",
    "        val_ratio=val_ratio,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    dataloaders = create_dataloaders(\n",
    "        split_data,\n",
    "        device_type=device_type,\n",
    "        batch_size=adjusted_batch_size,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nDataset Summary:\")\n",
    "        for split in ['train', 'val']:\n",
    "            print(f\"\\n{split.capitalize()} set sizes:\")\n",
    "            for condition in config['core_conditions']:\n",
    "                if condition in split_data[split]:\n",
    "                    print(f\"{condition}: {len(split_data[split][condition])}\")\n",
    "        \n",
    "        # Print memory usage information\n",
    "        if device_type == \"cuda\":\n",
    "            print(\"\\nGPU Memory Usage:\")\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "        elif device_type == \"tpu\":\n",
    "            try:\n",
    "                import torch_xla.debug.metrics as met\n",
    "                print(\"\\nTPU Memory Usage:\")\n",
    "                print(met.metrics_report())\n",
    "            except ImportError:\n",
    "                pass\n",
    "    \n",
    "    return dataloaders, split_data, config, device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f40dcd",
   "metadata": {
    "papermill": {
     "duration": 0.00538,
     "end_time": "2024-12-27T06:43:39.516632",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.511252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load & Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1e755b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:43:39.529631Z",
     "iopub.status.busy": "2024-12-27T06:43:39.529255Z",
     "iopub.status.idle": "2024-12-27T06:44:43.362192Z",
     "shell.execute_reply": "2024-12-27T06:44:43.361018Z"
    },
    "papermill": {
     "duration": 63.848144,
     "end_time": "2024-12-27T06:44:43.370451",
     "exception": false,
     "start_time": "2024-12-27T06:43:39.522307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cpu (cpu)\n",
      "\n",
      "Dataset successfully loaded\n",
      "\n",
      "Dataset Summary:\n",
      "\n",
      "spinal_canal_stenosis:\n",
      "Total samples: 9753\n",
      "  Normal/Mild: 8552\n",
      "  Moderate: 732\n",
      "  Severe: 469\n",
      "\n",
      "left_neural_foraminal_narrowing:\n",
      "Total samples: 9860\n",
      "  Normal/Mild: 7671\n",
      "  Moderate: 1792\n",
      "  Severe: 397\n",
      "\n",
      "right_neural_foraminal_narrowing:\n",
      "Total samples: 9829\n",
      "  Normal/Mild: 7684\n",
      "  Moderate: 1767\n",
      "  Severe: 378\n",
      "\n",
      "left_subarticular_stenosis:\n",
      "Total samples: 9603\n",
      "  Normal/Mild: 6857\n",
      "  Moderate: 1834\n",
      "  Severe: 912\n",
      "\n",
      "right_subarticular_stenosis:\n",
      "Total samples: 9612\n",
      "  Normal/Mild: 6862\n",
      "  Moderate: 1825\n",
      "  Severe: 925\n",
      "\n",
      "Dataset Summary:\n",
      "\n",
      "Train set sizes:\n",
      "spinal_canal_stenosis: 7803\n",
      "left_neural_foraminal_narrowing: 7888\n",
      "right_neural_foraminal_narrowing: 7864\n",
      "left_subarticular_stenosis: 7683\n",
      "right_subarticular_stenosis: 7690\n",
      "\n",
      "Val set sizes:\n",
      "spinal_canal_stenosis: 1950\n",
      "left_neural_foraminal_narrowing: 1972\n",
      "right_neural_foraminal_narrowing: 1965\n",
      "left_subarticular_stenosis: 1920\n",
      "right_subarticular_stenosis: 1922\n"
     ]
    }
   ],
   "source": [
    "dataloaders, split_data, config, device = load_and_prepare_data(\n",
    "    base_load_path=\"/kaggle/input/degenerative-spine-image-classificaton/processed_spine_dataset\",\n",
    "    batch_size=32,\n",
    "    val_ratio=0.2,\n",
    "    verbose=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71029de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:43.384201Z",
     "iopub.status.busy": "2024-12-27T06:44:43.383277Z",
     "iopub.status.idle": "2024-12-27T06:44:43.390309Z",
     "shell.execute_reply": "2024-12-27T06:44:43.389169Z"
    },
    "papermill": {
     "duration": 0.016179,
     "end_time": "2024-12-27T06:44:43.392455",
     "exception": false,
     "start_time": "2024-12-27T06:44:43.376276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def get_validation_subset(val_data: Dataset, subset_size: int, seed: int = 42) -> Subset:\n",
    "    \"\"\"\n",
    "    Extract a subset from the validation dataset.\n",
    "\n",
    "    Args:\n",
    "        val_data (Dataset): The validation dataset.\n",
    "        subset_size (int): The number of samples to include in the subset.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Subset: A subset of the validation dataset.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    indices = torch.randperm(len(val_data))[:subset_size]  # Randomly sample indices\n",
    "    return Subset(val_data, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42adb9cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:43.406259Z",
     "iopub.status.busy": "2024-12-27T06:44:43.405217Z",
     "iopub.status.idle": "2024-12-27T06:44:43.421030Z",
     "shell.execute_reply": "2024-12-27T06:44:43.420154Z"
    },
    "papermill": {
     "duration": 0.024803,
     "end_time": "2024-12-27T06:44:43.423163",
     "exception": false,
     "start_time": "2024-12-27T06:44:43.398360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define conditions\n",
    "conditions = [\n",
    "    \"spinal_canal_stenosis\",\n",
    "    \"left_neural_foraminal_narrowing\",\n",
    "    \"right_neural_foraminal_narrowing\",\n",
    "    \"left_subarticular_stenosis\",\n",
    "    \"right_subarticular_stenosis\"\n",
    "]\n",
    "\n",
    "subset_size = 100\n",
    "val_subset_loaders = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    val_dataset = split_data['val'][condition]\n",
    "    val_subset = get_validation_subset(val_dataset, subset_size)\n",
    "    val_subset_loaders[condition] = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65a5d4",
   "metadata": {
    "papermill": {
     "duration": 0.005636,
     "end_time": "2024-12-27T06:44:43.434696",
     "exception": false,
     "start_time": "2024-12-27T06:44:43.429060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Spinal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f6de24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:43.448214Z",
     "iopub.status.busy": "2024-12-27T06:44:43.447827Z",
     "iopub.status.idle": "2024-12-27T06:44:43.471865Z",
     "shell.execute_reply": "2024-12-27T06:44:43.470816Z"
    },
    "papermill": {
     "duration": 0.033403,
     "end_time": "2024-12-27T06:44:43.473768",
     "exception": false,
     "start_time": "2024-12-27T06:44:43.440365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, Tuple\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class ModelArchitecture(str, Enum):\n",
    "    \"\"\"Supported model architectures\"\"\"\n",
    "    INCEPTION_V4 = \"inception_v4\"\n",
    "    EFFICIENTNET = \"efficientnet_b0\"\n",
    "    EFFICIENTNET_V2 = \"efficientnetv2_s\"\n",
    "    VGG16 = \"vgg16\"\n",
    "\n",
    "\n",
    "class SpinalModel(nn.Module):\n",
    "    \"\"\"Enhanced neural network model for spinal condition classification\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        architecture: ModelArchitecture,\n",
    "        num_classes: int,\n",
    "        pretrained: bool = True,\n",
    "        dropout_rate: float = 0.5,\n",
    "        weight_decay: float = 5e-3,\n",
    "        unfreeze_layers: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.architecture = architecture\n",
    "        self.num_classes = num_classes\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Get the best available device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Create the backbone model\n",
    "        self.backbone = self._create_backbone(pretrained)\n",
    "        \n",
    "        # Apply partial freezing of layers\n",
    "        self.partial_freeze_backbone(unfreeze_layers)\n",
    "        \n",
    "        # Get the number of features from the backbone\n",
    "        num_features = self._get_num_features()\n",
    "        \n",
    "        # Enhanced classifier with residual connections\n",
    "        self.classifier = self._create_classifier(num_features, dropout_rate)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Move model to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _create_backbone(self, pretrained: bool) -> nn.Module:\n",
    "        \"\"\"Create the backbone model\"\"\"\n",
    "        if self.architecture == ModelArchitecture.INCEPTION_V4:\n",
    "            model = timm.create_model('inception_v4.tf_in1k', pretrained=pretrained, num_classes=0)\n",
    "        elif self.architecture == ModelArchitecture.EFFICIENTNET:\n",
    "            model = timm.create_model('efficientnet_b0.ra4_e3600_r224_in1k', pretrained=pretrained, num_classes=0)\n",
    "        elif self.architecture == ModelArchitecture.EFFICIENTNET_V2:\n",
    "            model = timm.create_model('tf_efficientnetv2_s.in21k_ft_in1k', pretrained=pretrained, num_classes=0)\n",
    "        elif self.architecture == ModelArchitecture.VGG16:\n",
    "            model = timm.create_model('vgg16.tv_in1k', pretrained=pretrained, num_classes=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported architecture: {self.architecture}\")\n",
    "        return model\n",
    "\n",
    "    def _get_num_features(self) -> int:\n",
    "        \"\"\"Get number of features from backbone\"\"\"\n",
    "        if self.architecture == ModelArchitecture.INCEPTION_V4:\n",
    "            return 1536\n",
    "        elif self.architecture in [ModelArchitecture.EFFICIENTNET, ModelArchitecture.EFFICIENTNET_V2]:\n",
    "            return 1280\n",
    "        elif self.architecture == ModelArchitecture.VGG16:\n",
    "            return 4096\n",
    "        raise ValueError(f\"Unsupported architecture: {self.architecture}\")\n",
    "\n",
    "    def _create_classifier(self, num_features: int, dropout_rate: float) -> nn.Sequential:\n",
    "        \"\"\"Create classifier with residual connections\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Identity(),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            \n",
    "            # First dense block\n",
    "            self._create_dense_block(num_features, 512, dropout_rate),\n",
    "            \n",
    "            # Second dense block\n",
    "            self._create_dense_block(512, 256, dropout_rate),\n",
    "            \n",
    "            # Final classification\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def _create_dense_block(self, in_features: int, out_features: int, dropout_rate: float) -> nn.Sequential:\n",
    "        \"\"\"Create a dense block with batch norm and dropout\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def partial_freeze_backbone(self, unfreeze_layers: int):\n",
    "        \"\"\"Partially freeze backbone layers\"\"\"\n",
    "        if unfreeze_layers == 0:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "            return\n",
    "            \n",
    "        parameters = list(self.backbone.named_parameters())\n",
    "        total_layers = len(parameters)\n",
    "        \n",
    "        # Freeze all layers first\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Unfreeze the specified number of layers from the bottom\n",
    "        for i in range(max(0, total_layers - unfreeze_layers), total_layers):\n",
    "            parameters[i][1].requires_grad = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        x = x.to(self.device)\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def create_model(\n",
    "    architecture: str,\n",
    "    num_classes: int,\n",
    "    pretrained: bool = True,\n",
    "    dropout_rate: float = 0.5,\n",
    "    weight_decay: float = 5e-3,\n",
    "    unfreeze_layers: int = 0,\n",
    "    verbose: bool = False\n",
    ") -> Tuple[SpinalModel, Dict[str, Any]]:\n",
    "    \"\"\"Create a model instance\"\"\"\n",
    "    try:\n",
    "        arch = ModelArchitecture(architecture.lower())\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            f\"Unsupported architecture: {architecture}. \"\n",
    "            f\"Supported architectures: {[a.value for a in ModelArchitecture]}\"\n",
    "        )\n",
    "    \n",
    "    # Create model\n",
    "    model = SpinalModel(\n",
    "        architecture=arch,\n",
    "        num_classes=num_classes,\n",
    "        pretrained=pretrained,\n",
    "        dropout_rate=dropout_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        unfreeze_layers=unfreeze_layers\n",
    "    )\n",
    "    \n",
    "    # Get preprocessing parameters\n",
    "    preprocess_params = {\n",
    "        'image_size': 299 if arch == ModelArchitecture.INCEPTION_V4 else 224,\n",
    "        'mean': [0.485, 0.456, 0.406],\n",
    "        'std': [0.229, 0.224, 0.225],\n",
    "        'device': model.device\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nModel Configuration:\")\n",
    "        print(f\"Architecture: {arch.value}\")\n",
    "        # print(f\"Device: {preprocess_params['device']} ({preprocess_params['device_type']})\")\n",
    "        print(f\"Input size: {preprocess_params['image_size']}x{preprocess_params['image_size']}\")\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "        print(f\"Pretrained: {pretrained}\")\n",
    "        \n",
    "        # Print model summary if torchinfo is available\n",
    "        try:\n",
    "            from torchsummary import summary\n",
    "            # Assuming 'model' is your SpinalModel\n",
    "            input_size = (3, preprocess_params['image_size'], preprocess_params['image_size'])\n",
    "            summary(model, input_size=input_size)\n",
    "        except ImportError:\n",
    "            if verbose:\n",
    "                print(\"\\nInstall torchsummary for detailed model summary\")\n",
    "    \n",
    "    return model, preprocess_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b44dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:43.487381Z",
     "iopub.status.busy": "2024-12-27T06:44:43.487040Z",
     "iopub.status.idle": "2024-12-27T06:44:50.004797Z",
     "shell.execute_reply": "2024-12-27T06:44:50.003581Z"
    },
    "papermill": {
     "duration": 6.527407,
     "end_time": "2024-12-27T06:44:50.007221",
     "exception": false,
     "start_time": "2024-12-27T06:44:43.479814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8588f0b3462a45ca93132babccc0b191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "Architecture: vgg16\n",
      "Input size: 224x224\n",
      "Number of classes: 3\n",
      "Pretrained: True\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "           Conv2d-32           [-1, 4096, 1, 1]     102,764,544\n",
      "             ReLU-33           [-1, 4096, 1, 1]               0\n",
      "          Dropout-34           [-1, 4096, 1, 1]               0\n",
      "           Conv2d-35           [-1, 4096, 1, 1]      16,781,312\n",
      "             ReLU-36           [-1, 4096, 1, 1]               0\n",
      "          ConvMlp-37           [-1, 4096, 1, 1]               0\n",
      "AdaptiveAvgPool2d-38           [-1, 4096, 1, 1]               0\n",
      "          Flatten-39                 [-1, 4096]               0\n",
      "SelectAdaptivePool2d-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "         Identity-42                 [-1, 4096]               0\n",
      "         Identity-43                 [-1, 4096]               0\n",
      "   ClassifierHead-44                 [-1, 4096]               0\n",
      "              VGG-45                 [-1, 4096]               0\n",
      "         Identity-46                 [-1, 4096]               0\n",
      "          Flatten-47                 [-1, 4096]               0\n",
      "      BatchNorm1d-48                 [-1, 4096]           8,192\n",
      "          Dropout-49                 [-1, 4096]               0\n",
      "           Linear-50                  [-1, 512]       2,097,664\n",
      "             ReLU-51                  [-1, 512]               0\n",
      "      BatchNorm1d-52                  [-1, 512]           1,024\n",
      "          Dropout-53                  [-1, 512]               0\n",
      "           Linear-54                  [-1, 256]         131,328\n",
      "             ReLU-55                  [-1, 256]               0\n",
      "      BatchNorm1d-56                  [-1, 256]             512\n",
      "          Dropout-57                  [-1, 256]               0\n",
      "      BatchNorm1d-58                  [-1, 256]             512\n",
      "          Dropout-59                  [-1, 256]               0\n",
      "           Linear-60                    [-1, 3]             771\n",
      "================================================================\n",
      "Total params: 136,500,547\n",
      "Trainable params: 133,584,899\n",
      "Non-trainable params: 2,915,648\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.98\n",
      "Params size (MB): 520.71\n",
      "Estimated Total Size (MB): 740.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model, preprocess_params = create_model(\n",
    "    architecture=\"vgg16\",  # or \"efficientnet\" or \"efficientnet_v2\"\n",
    "    num_classes=3,\n",
    "    pretrained=True,\n",
    "    verbose=True,\n",
    "    unfreeze_layers=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56509131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:50.022152Z",
     "iopub.status.busy": "2024-12-27T06:44:50.021698Z",
     "iopub.status.idle": "2024-12-27T06:44:54.963822Z",
     "shell.execute_reply": "2024-12-27T06:44:54.962642Z"
    },
    "papermill": {
     "duration": 4.952077,
     "end_time": "2024-12-27T06:44:54.966139",
     "exception": false,
     "start_time": "2024-12-27T06:44:50.014062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/3626930169.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/kaggle/input/rsna-lumbar-dataset-vgg16-class/checkpoints/checkpoint_best.pth', map_location=model.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpinalModel(\n",
       "  (backbone): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (pre_logits): ConvMlp(\n",
       "      (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Identity()\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Identity()\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/kaggle/input/rsna-lumbar-dataset-vgg16-class/checkpoints/checkpoint_best.pth', map_location=model.device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # If using for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91399c9",
   "metadata": {
    "papermill": {
     "duration": 0.006432,
     "end_time": "2024-12-27T06:44:54.979338",
     "exception": false,
     "start_time": "2024-12-27T06:44:54.972906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a927d9fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:54.994052Z",
     "iopub.status.busy": "2024-12-27T06:44:54.993640Z",
     "iopub.status.idle": "2024-12-27T06:44:55.010905Z",
     "shell.execute_reply": "2024-12-27T06:44:55.009839Z"
    },
    "papermill": {
     "duration": 0.02728,
     "end_time": "2024-12-27T06:44:55.013043",
     "exception": false,
     "start_time": "2024-12-27T06:44:54.985763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(\n",
    "   model: nn.Module,\n",
    "   test_loaders: Dict[str, DataLoader],\n",
    "   num_classes: int,\n",
    "   save_dir: str,\n",
    "   threshold: float = 0.5,\n",
    "   device: Optional[torch.device] = None\n",
    ") -> Dict:\n",
    "   model.eval()\n",
    "   device = device or model.device\n",
    "   metrics = {}\n",
    "   \n",
    "   Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "   \n",
    "   for condition, loader in test_loaders.items():\n",
    "       all_preds, all_labels, all_probs, all_images = [], [], [], []\n",
    "       \n",
    "       with torch.no_grad():\n",
    "           for inputs, labels in loader:\n",
    "               inputs = inputs.to(device, non_blocking=True)\n",
    "               labels = labels.to(device, non_blocking=True)\n",
    "               \n",
    "               outputs = model(inputs)\n",
    "               probs = torch.softmax(outputs, dim=1)\n",
    "               preds = torch.argmax(probs, dim=1)\n",
    "               \n",
    "               all_preds.extend(preds.cpu().numpy())\n",
    "               all_probs.extend(probs.cpu().numpy())\n",
    "               all_labels.extend(labels.cpu().numpy())\n",
    "               all_images.extend(inputs.cpu().numpy())\n",
    "       \n",
    "       all_preds = np.array(all_preds)\n",
    "       all_probs = np.array(all_probs)\n",
    "       all_labels = np.array(all_labels)\n",
    "       all_images = np.array(all_images)\n",
    "       \n",
    "       # Visualization\n",
    "       num_samples = min(10, len(all_images))\n",
    "       fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "       \n",
    "       for i in range(num_samples):\n",
    "           img = all_images[i].transpose(1, 2, 0)\n",
    "           img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "           img = np.clip(img, 0, 1)\n",
    "           \n",
    "           axes[i, 0].imshow(img)\n",
    "           axes[i, 0].set_title(f'Image {i}')\n",
    "           \n",
    "           axes[i, 1].bar(range(num_classes), np.eye(num_classes)[all_labels[i]])\n",
    "           axes[i, 1].set_title(f'True: {all_labels[i]}')\n",
    "           \n",
    "           axes[i, 2].bar(range(num_classes), all_probs[i])\n",
    "           axes[i, 2].set_title(f'Pred: {all_preds[i]} ({all_probs[i][all_preds[i]]:.2f})')\n",
    "           \n",
    "       plt.tight_layout()\n",
    "       plt.savefig(os.path.join(save_dir, f'{condition}_results.png'))\n",
    "       plt.close()\n",
    "       \n",
    "       # Metrics\n",
    "       metrics[condition] = {\n",
    "           'accuracy': accuracy_score(all_labels, all_preds),\n",
    "           'confusion_matrix': confusion_matrix(all_labels, all_preds),\n",
    "           'per_class_accuracy': [],\n",
    "           'roc_auc_scores': [],\n",
    "           'pr_auc_scores': []\n",
    "       }\n",
    "       \n",
    "       for i in range(num_classes):\n",
    "           class_labels = (all_labels == i).astype(int)\n",
    "           class_probs = all_probs[:, i]\n",
    "           class_preds = (all_preds == i).astype(int)\n",
    "           \n",
    "           metrics[condition]['roc_auc_scores'].append(roc_auc_score(class_labels, class_probs))\n",
    "           precision, recall, _ = precision_recall_curve(class_labels, class_probs)\n",
    "           metrics[condition]['pr_auc_scores'].append(auc(recall, precision))\n",
    "           metrics[condition]['per_class_accuracy'].append(accuracy_score(class_labels, class_preds))\n",
    "       \n",
    "       metrics[condition].update({\n",
    "           'avg_roc_auc': np.mean(metrics[condition]['roc_auc_scores']),\n",
    "           'avg_pr_auc': np.mean(metrics[condition]['pr_auc_scores']),\n",
    "           'avg_accuracy': np.mean(metrics[condition]['per_class_accuracy'])\n",
    "       })\n",
    "       \n",
    "       print(f\"\\nResults for {condition}:\")\n",
    "       print(f\"Average ROC AUC: {metrics[condition]['avg_roc_auc']:.4f}\")\n",
    "       print(f\"Average PR AUC: {metrics[condition]['avg_pr_auc']:.4f}\")\n",
    "       print(f\"Average Accuracy: {metrics[condition]['avg_accuracy']:.4f}\")\n",
    "       print(\"\\nConfusion Matrix:\")\n",
    "       print(metrics[condition]['confusion_matrix'])\n",
    "   \n",
    "   return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bf249cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T06:44:55.028673Z",
     "iopub.status.busy": "2024-12-27T06:44:55.028281Z",
     "iopub.status.idle": "2024-12-27T06:46:35.975881Z",
     "shell.execute_reply": "2024-12-27T06:46:35.974680Z"
    },
    "papermill": {
     "duration": 100.958398,
     "end_time": "2024-12-27T06:46:35.978200",
     "exception": false,
     "start_time": "2024-12-27T06:44:55.019802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for spinal_canal_stenosis:\n",
      "Average ROC AUC: 0.7064\n",
      "Average PR AUC: 0.3953\n",
      "Average Accuracy: 0.6600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42 31 14]\n",
      " [ 1  5  3]\n",
      " [ 1  1  2]]\n",
      "\n",
      "Results for left_neural_foraminal_narrowing:\n",
      "Average ROC AUC: 0.7022\n",
      "Average PR AUC: 0.4028\n",
      "Average Accuracy: 0.5867\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32 39 12]\n",
      " [ 1  4  8]\n",
      " [ 0  2  2]]\n",
      "\n",
      "Results for right_neural_foraminal_narrowing:\n",
      "Average ROC AUC: 0.5941\n",
      "Average PR AUC: 0.4057\n",
      "Average Accuracy: 0.5400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24 37 16]\n",
      " [ 4  5  9]\n",
      " [ 1  2  2]]\n",
      "\n",
      "Results for left_subarticular_stenosis:\n",
      "Average ROC AUC: 0.8435\n",
      "Average PR AUC: 0.5966\n",
      "Average Accuracy: 0.7667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46 15  9]\n",
      " [ 0 14  9]\n",
      " [ 0  2  5]]\n",
      "\n",
      "Results for right_subarticular_stenosis:\n",
      "Average ROC AUC: 0.7691\n",
      "Average PR AUC: 0.5216\n",
      "Average Accuracy: 0.6867\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37 27  4]\n",
      " [ 1 10 11]\n",
      " [ 0  4  6]]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "test_metrics = test_model(\n",
    "   model=model,\n",
    "   test_loaders=val_subset_loaders,\n",
    "   num_classes=3,\n",
    "   save_dir='./checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d271237",
   "metadata": {
    "papermill": {
     "duration": 0.006931,
     "end_time": "2024-12-27T06:46:35.992166",
     "exception": false,
     "start_time": "2024-12-27T06:46:35.985235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5986261,
     "sourceId": 9772858,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 214700703,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214833107,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214840028,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 193.711184,
   "end_time": "2024-12-27T06:46:38.618688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-27T06:43:24.907504",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "096cb54c3dee46edbe0f18ac4b93f295": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c7621a54e6e4a43a286102d30969db2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8c35a96fd9544418a5bda7f3b7da728",
       "placeholder": "​",
       "style": "IPY_MODEL_d098d3e2d82e4097985f1750b73ef1dd",
       "value": "model.safetensors: 100%"
      }
     },
     "8588f0b3462a45ca93132babccc0b191": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4c7621a54e6e4a43a286102d30969db2",
        "IPY_MODEL_a2127f0cbc184f438080315c24985869",
        "IPY_MODEL_96fc6e75261343b7bd9766873dda11c9"
       ],
       "layout": "IPY_MODEL_c75c08d9ce81423081fae92b6ccc1fe3"
      }
     },
     "9229156122294526a44a010a9de8c3bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96fc6e75261343b7bd9766873dda11c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_096cb54c3dee46edbe0f18ac4b93f295",
       "placeholder": "​",
       "style": "IPY_MODEL_aa935223d1d943a88852ef55b4a42efb",
       "value": " 553M/553M [00:02&lt;00:00, 228MB/s]"
      }
     },
     "a2127f0cbc184f438080315c24985869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9229156122294526a44a010a9de8c3bf",
       "max": 553432986.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f3ffffd4324249b59bc24722bcdd7f3c",
       "value": 553432986.0
      }
     },
     "aa935223d1d943a88852ef55b4a42efb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c75c08d9ce81423081fae92b6ccc1fe3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d098d3e2d82e4097985f1750b73ef1dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f3ffffd4324249b59bc24722bcdd7f3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f8c35a96fd9544418a5bda7f3b7da728": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
